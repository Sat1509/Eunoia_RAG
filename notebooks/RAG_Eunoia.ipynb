{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "27ad9499",
   "metadata": {},
   "source": [
    "# Eunoia: A RAG-based Generative AI for Women's Health\n",
    "\n",
    "This project implements a **Retrieval-Augmented Generation (RAG)** system to provide **accurate and context-aware answers** on women’s health topics.  \n",
    "\n",
    "- RAG combines **retrieval-based methods** with **generative AI**, enabling the model to access **external knowledge sources dynamically** while generating responses.  \n",
    "- This ensures that answers are **factually grounded**, reducing hallucinations that are common in standard generative models.  \n",
    "- The system is designed to assist users with **common health questions, symptom guidance, and educational content** in a **reliable and explainable** manner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edc61a23",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from pathlib import Path\n",
    "from docling.document_converter import DocumentConverter\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "# Folder with input PDFs\n",
    "input_folder = Path('/Users/sathammai/Desktop/Research Paper')\n",
    "# Folder to save Markdown outputs\n",
    "output_folder = Path('/Users/sathammai/Desktop/ResearchPaper_Markups')\n",
    "output_folder.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "converter = DocumentConverter()\n",
    "\n",
    "# Iterate over all PDFs in the input folder\n",
    "for pdf_path in input_folder.glob('*.pdf'):\n",
    "    logging.info(f'Processing {pdf_path.name}...')\n",
    "\n",
    "    # Convert PDF\n",
    "    result = converter.convert(pdf_path)\n",
    "\n",
    "    # Markdown filename = same as PDF but with .md extension\n",
    "    md_filename = output_folder / f\"{pdf_path.stem}.md\"\n",
    "\n",
    "    # Save Markdown\n",
    "    result.document.save_as_markdown(md_filename)\n",
    "    logging.info(f\"Saved Markdown: {md_filename}\")\n",
    "\n",
    "print(\"All PDFs converted to Markdown!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7da4fd27",
   "metadata": {},
   "source": [
    "## Preprocessing\n",
    "\n",
    "1. Medical papers covering various aspects of women’s health were **manually collected**.  \n",
    "2. Texts were **extracted from the PDFs** and converted to Markdown using `docling`, preserving headings and structure.  \n",
    "3. The Markdown documents were then **broken into chunks** based on subheadings or a **word range of 300–600 words**.  \n",
    "   - A **chunk overlap of 100 words** was maintained to preserve context between consecutive chunks.  \n",
    "   - Chunks with fewer than 50 words were **merged with the previous chunk** to avoid tiny, context-less passages.  \n",
    "\n",
    "These steps ensure that each chunk is **self-contained, coherent, and suitable for retrieval**, enabling the RAG system to generate **accurate and context-aware responses**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03fb6531",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def smart_hybrid_chunk(text, min_words=300, max_words=600, chunk_overlap=100, tiny_threshold=50):\n",
    "    # Split on headings\n",
    "    heading_split_pattern = r\"(#+\\s.*\\n)\"\n",
    "    parts = re.split(heading_split_pattern, text)\n",
    "    parts = [p.strip() for p in parts if p.strip()]\n",
    "\n",
    "    chunks = []\n",
    "    buffer = \"\"\n",
    "\n",
    "    for part in parts:\n",
    "        part_words = part.split()\n",
    "        buffer_words = buffer.split()\n",
    "\n",
    "        # If adding this part keeps us under max_words, append it\n",
    "        if len(buffer_words) + len(part_words) <= max_words:\n",
    "            buffer += \" \" + part if buffer else part\n",
    "        else:\n",
    "            # If buffer is big enough, finalize it\n",
    "            if buffer_words:\n",
    "                chunks.append(buffer.strip())\n",
    "            # If part itself is bigger than max_words, split it\n",
    "            while len(part_words) > max_words:\n",
    "                chunks.append(\" \".join(part_words[:max_words]))\n",
    "                part_words = part_words[max_words - chunk_overlap:]\n",
    "            buffer = \" \".join(part_words)\n",
    "\n",
    "    # Append any leftover buffer\n",
    "    if buffer:\n",
    "        chunks.append(buffer.strip())\n",
    "\n",
    "    # Merge tiny chunks smartly\n",
    "    final_chunks = []\n",
    "    i = 0\n",
    "    while i < len(chunks):\n",
    "        current = chunks[i]\n",
    "        current_words = current.split()\n",
    "\n",
    "        # Merge with next if tiny\n",
    "        while len(current_words) < tiny_threshold and i + 1 < len(chunks):\n",
    "            current += \" \" + chunks[i + 1]\n",
    "            current_words = current.split()\n",
    "            i += 1\n",
    "\n",
    "        # Merge with previous if still tiny\n",
    "        if len(current_words) < tiny_threshold and final_chunks:\n",
    "            final_chunks[-1] += \" \" + current\n",
    "        else:\n",
    "            final_chunks.append(current)\n",
    "\n",
    "        i += 1\n",
    "\n",
    "    return final_chunks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af5fa8a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "markdown_folder = Path('/Users/sathammai/Desktop/ResearchPaper_Markups')\n",
    "output_folder = Path('/Users/sathammai/Desktop/NewChunks')\n",
    "output_folder.mkdir(exist_ok=True)\n",
    "\n",
    "for md_file in markdown_folder.glob(\"*.md\"):\n",
    "    text = md_file.read_text(encoding=\"utf-8\")\n",
    "    chunks = smart_hybrid_chunk(text)\n",
    "\n",
    "    for i, chunk in enumerate(chunks):\n",
    "        chunk_file = output_folder / f\"{md_file.stem}_chunk_{i+1}.md\"\n",
    "        chunk_file.write_text(chunk, encoding=\"utf-8\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6ca785f",
   "metadata": {},
   "source": [
    "### Embedding Chunks using BioBERT\n",
    "\n",
    "- All text chunks were converted into **vector embeddings** using Hugging Face's **BioBERT** model.  \n",
    "  - **BioBERT** was chosen because it is pre-trained on biomedical and medical corpora, enabling it to **better capture subtle distinctions in medical terminology** compared to a standard BERT model.\n",
    "\n",
    "- For each chunk, embeddings were obtained by **mean pooling over all token embeddings** rather than using the `[CLS]` token.  \n",
    "  - Although mean pooling is slightly more computationally expensive, it provides a **more representative vector** of the entire chunk by aggregating information from all tokens.  \n",
    "  - Positional information is already encoded within the token embeddings, so mean pooling effectively summarizes the semantic content of the chunk.\n",
    "\n",
    "- Each chunk was **tokenized** and passed through BioBERT to compute its **embedding vector**, which forms the knowledge base for the RAG retriever.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72a89f6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "import os\n",
    "\n",
    "# 1. Load BioBERT\n",
    "model_name = \"dmis-lab/biobert-base-cased-v1.1\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModel.from_pretrained(model_name)\n",
    "model.eval()  # ensure we're in evaluation mode\n",
    "\n",
    "# 2. Mean pooling function\n",
    "def mean_pooling(model_output, attention_mask):\n",
    "    token_embeddings = model_output.last_hidden_state  # [batch_size, seq_len, hidden_dim]\n",
    "    input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n",
    "    sum_embeddings = torch.sum(token_embeddings * input_mask_expanded, dim=1)\n",
    "    sum_mask = torch.clamp(input_mask_expanded.sum(dim=1), min=1e-9)\n",
    "    return sum_embeddings / sum_mask\n",
    "\n",
    "# 3. Folder with chunks\n",
    "chunks_folder = \"/Users/sathammai/Desktop/NewerChunks\"\n",
    "all_chunks = []\n",
    "\n",
    "# Read all .md files\n",
    "for filename in os.listdir(chunks_folder):\n",
    "    if filename.endswith(\".md\"):\n",
    "        with open(os.path.join(chunks_folder, filename), \"r\", encoding=\"utf-8\") as f:\n",
    "            chunk_text = f.read().strip()\n",
    "            if chunk_text:  # only add non-empty chunks\n",
    "                all_chunks.append(chunk_text)\n",
    "\n",
    "print(f\"Total non-empty chunks: {len(all_chunks)}\")\n",
    "\n",
    "# 4. Tokenize and embed all chunks\n",
    "def embed_texts(texts, max_length=512):\n",
    "    encoded_input = tokenizer(\n",
    "        texts, padding=True, truncation=True, return_tensors=\"pt\", max_length=max_length\n",
    "    )\n",
    "    with torch.no_grad():\n",
    "        model_output = model(**encoded_input)\n",
    "    embeddings = mean_pooling(model_output, encoded_input['attention_mask'])\n",
    "    return embeddings\n",
    "\n",
    "# 5. Compute embeddings\n",
    "embeddings = embed_texts(all_chunks)\n",
    "\n",
    "print(\"Number of chunks:\", len(all_chunks))\n",
    "print(\"Shape of embeddings:\", embeddings.shape)  # [num_chunks, hidden_dim]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8649ee5",
   "metadata": {},
   "source": [
    "### Storing Embeddings in ChromaDB\n",
    "\n",
    "- The chunk embeddings generated by BioBERT were stored in **ChromaDB**, a vector database that supports **efficient similarity search**.  \n",
    "- While ChromaDB may not be the most advanced or production-grade solution, it was chosen here for **prototyping purposes**.  \n",
    "- This setup allows the **RAG system** to quickly retrieve relevant chunks during inference.  \n",
    "- The database can be **switched to a more robust solution** (e.g., Milvus, Pinecone, or Weaviate) in the future without changing the overall architecture.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82cf01b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install chromadb\n",
    "\n",
    "import chromadb\n",
    "from chromadb.utils import embedding_functions\n",
    "\n",
    "# Initialize client\n",
    "client = chromadb.Client()\n",
    "\n",
    "# Create collection (name it relevantly)\n",
    "collection = client.create_collection(\n",
    "    name=\"womens_health\", \n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "341f9b7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Convert embeddings to list\n",
    "embeddings_list = embeddings.tolist()\n",
    "\n",
    "# Create IDs for each chunk\n",
    "ids = [str(i) for i in range(len(all_chunks))]\n",
    "\n",
    "# Insert into collection\n",
    "collection.add(\n",
    "    ids=ids,\n",
    "    embeddings=embeddings_list,\n",
    "    metadatas=[{\"text\": text} for text in all_chunks],\n",
    "    documents=all_chunks\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9decbcfa-0b1d-48c2-8c34-efb6f12c79b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ollama pull llama3.2\n",
    "!ollama run llama3.2\n",
    "!pip install tensorflow==2.19.0 tensorboard==2.19.0 tf-keras==2.19.0 --quiet\n",
    "!pip install tf-keras --quiet\n",
    "!pip install -U langchain-chroma --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3308eef3",
   "metadata": {},
   "source": [
    "## RAG-based QA Pipeline\n",
    "\n",
    "This code implements the **final Retrieval-Augmented Generation (RAG) pipeline** for answering women's health queries:\n",
    "\n",
    "1. **Query input:**  \n",
    "   - The user provides a question in natural language (e.g., `\"What are the common symptoms of PCOS?\"`).\n",
    "\n",
    "2. **Query embedding & retrieval:**  \n",
    "   - The query is **embedded using BioBERT** and compared against the **precomputed chunk embeddings** stored in ChromaDB.  \n",
    "   - The **top-k most relevant chunks** are retrieved to serve as the context for the LLM.\n",
    "\n",
    "3. **Prompting the LLM:**  \n",
    "   - The retrieved context is inserted into a **prompt template** and passed to **LLaMA 3.2** via Ollama.  \n",
    "   - The prompt instructs the model to **answer concisely, accurately, and based only on the provided context**.\n",
    "\n",
    "4. **Answer generation:**  \n",
    "   - The LLM generates a **grounded answer** based on the retrieved chunks.  \n",
    "   - Both the **answer** and the **source documents** used for retrieval are returned for transparency and verification.\n",
    "\n",
    "This pipeline ensures that answers are **factually informed**, context-aware, and traceable to the original source documents.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef7209bf-46cc-4941-bea0-0867c0daad83",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No sentence-transformers model found with name dmis-lab/biobert-base-cased-v1.1. Creating a new one with mean pooling.\n",
      "/var/folders/9l/df9_2mms641gnrqbbzclfplh0000gn/T/ipykernel_33298/1301528120.py:68: LangChainDeprecationWarning: The method `Chain.__call__` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  result = qa_chain(query)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: PCOS (Polycystic Ovary Syndrome) is a hormonal disorder that affects women of reproductive age. The common symptoms of PCOS include:\n",
      "\n",
      "* Irregular menstrual cycles or amenorrhea (absence of periods)\n",
      "* Weight gain and obesity\n",
      "* Acne\n",
      "* Excess hair growth on the face, chest, back, and buttocks\n",
      "* Male pattern baldness\n",
      "* Cysts on the ovaries (detected by ultrasound)\n",
      "* Infertility or difficulty getting pregnant\n",
      "* High levels of androgens (male hormones) in the blood\n",
      "* Insulin resistance and high blood sugar levels\n",
      "\n",
      "These symptoms can vary in severity and may not be present in all women with PCOS.\n",
      "Source docs: [{}, {}, {}, {}, {}]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from langchain_community.llms import Ollama\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_chroma import Chroma\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# Load LLaMA 3.2 via Ollama\n",
    "# -----------------------------\n",
    "llm = Ollama(model=\"llama3.2\", temperature=0.2)\n",
    "\n",
    "# -----------------------------\n",
    "# Connect ChromaDB with BioBERT embeddings\n",
    "# -----------------------------\n",
    "embeddings = HuggingFaceEmbeddings(\n",
    "    model_name=\"dmis-lab/biobert-base-cased-v1.1\"\n",
    ")\n",
    "\n",
    "vectordb = Chroma(\n",
    "    collection_name=\"womens_health\",\n",
    "    embedding_function=embeddings,\n",
    "    persist_directory=\"./chroma_db\"  \n",
    ")\n",
    "\n",
    "# -----------------------------\n",
    "# Create a Prompt Template\n",
    "# -----------------------------\n",
    "prompt_template = \"\"\"\n",
    "You are a knowledgeable medical assistant specialized in women's reproductive health.\n",
    "Answer the user's question based on the following context. Be concise, clear, and accurate.\n",
    "If the answer is not in the context, say \"Not enough information provided.\"\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "Question:\n",
    "{question}\n",
    "\n",
    "Answer:\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template=prompt_template,\n",
    "    input_variables=[\"context\", \"question\"]\n",
    ")\n",
    "\n",
    "# -----------------------------\n",
    "# Build the RAG QA Chain\n",
    "# -----------------------------\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    retriever=vectordb.as_retriever(search_kwargs={\"k\": 5}),\n",
    "    chain_type=\"stuff\",\n",
    "    chain_type_kwargs={\"prompt\": prompt},\n",
    "    return_source_documents=True\n",
    ")\n",
    "\n",
    "# -----------------------------\n",
    "# Test the chain with a query\n",
    "# -----------------------------\n",
    "query = \"What are the common symptoms of PCOS?\"\n",
    "result = qa_chain(query)\n",
    "\n",
    "print(\"Answer:\", result['result'])\n",
    "print(\"Source docs:\", [doc.metadata for doc in result['source_documents']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "de581b95-bcbd-486e-9b9c-efc7d502998c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The long-term metabolic and reproductive implications of PCOS in adolescents can be significant. Lifestyle interventions, such as diet and physical activity changes, have been shown to improve insulin sensitivity, reduce body mass index (BMI), and promote menstrual regularity. However, lifestyle modification alone may not be sufficient to mitigate all the effects of PCOS.\n",
      "\n",
      "Pharmacological treatments, particularly metformin, have also been found to be effective in improving metabolic outcomes, such as lowering BMI and subcutaneous adipose tissue, and promoting menstruation. The combination of lifestyle modification and metformin has been shown to have an additive effect on improving cardio-metabolic outcomes in high-risk groups.\n",
      "\n",
      "In terms of reproductive implications, lifestyle interventions can help improve fertility by regulating menstrual cycles and ovulation. Pharmacological treatments, such as birth control pills, may also be used to regulate menstrual cycles and reduce symptoms of hyperandrogenism.\n",
      "\n",
      "It's worth noting that the addition of pharmacological therapies is often indicated for women with PCOS who have severe clinical features, such as infertility or end-organ damage. In these cases, prescribing physicians should consider how medical management and lifestyle change can be used in adjunct to optimize treatment.\n",
      "\n",
      "Overall, a combination of lifestyle interventions and pharmacological treatments may be the most effective approach for managing PCOS in adolescents, with regular monitoring and adjustment of treatment plans as needed.\n"
     ]
    }
   ],
   "source": [
    "query = \"What are the long-term metabolic and reproductive implications of polycystic ovary syndrome (PCOS) in adolescents, and how do lifestyle interventions compare with pharmacological treatments in mitigating these effects?\"\n",
    "result = qa_chain({\"query\": query})\n",
    "print(result[\"result\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "40dc1b02-19df-4194-9dfb-2447135a89f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the provided context, here is a concise answer to your question:\n",
      "\n",
      "For patients undergoing laparoscopic excision of deep infiltrating endometriosis, the post-surgical recurrence rates are as follows:\n",
      "\n",
      "* Persistence or recurrence rate: 22% at 2 years and 40%-50% at 5 years\n",
      "* Advanced stage of disease: significantly fewer eggs collected, lower fertilization rate\n",
      "\n",
      "Fertility outcomes for patients undergoing laparoscopic excision of deep infiltrating endometriosis include:\n",
      "\n",
      "* Similar reproductive outcomes compared to those without the disease, although cycle cancellation rates are higher\n",
      "* Natural conception rates of 2% to 4.5% per 30 days for mild cases and <2% for moderate and severe cases\n",
      "\n",
      "Potential complications associated with laparoscopic excision of deep infiltrating endometriosis include:\n",
      "\n",
      "* Centralized pain before undergoing a hysterectomy, which may lead to refractory pain\n",
      "* Reduced ovarian reserve and function due to cystectomy (excision of endometriomas)\n",
      "\n",
      "The outcomes vary depending on the surgical technique used. A meta-analysis showed that excision of a cyst was associated with reduced rate of endometrioma recurrence, reduced symptom recurrence, and increased spontaneous pregnancy rates compared with ablative surgery.\n",
      "\n",
      "Adjunctive medical therapies may also be considered to improve post-surgical outcomes. However, there is limited evidence to support the effectiveness of these therapies in improving fertility outcomes or reducing recurrence rates.\n",
      "\n",
      "It's essential to note that individual results may vary, and patients should consult their healthcare provider for personalized guidance on managing endometriosis.\n"
     ]
    }
   ],
   "source": [
    "query = \"For patients undergoing laparoscopic excision of deep infiltrating endometriosis, what are the post-surgical recurrence rates, fertility outcomes, and potential complications, and how do these outcomes vary with different surgical techniques or adjunctive medical therapies?\"\n",
    "result = qa_chain({\"query\": query})\n",
    "print(result[\"result\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e5aebe8e-fa7e-4efb-891d-0a3f02d9f408",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aberrant inflammatory cytokine profiles and dysregulated estrogen receptor signaling play significant roles in the progression of endometriosis. Inflammation is a key component of endometriosis pathogenesis, with various cytokines contributing to the development and maintenance of ectopic lesions. Pro-inflammatory cytokines such as TNF-alpha, IL-1beta, and IL-6 promote inflammation, angiogenesis, and cell proliferation in endometriotic tissues.\n",
      "\n",
      "Dysregulated estrogen receptor signaling is also crucial in endometriosis. Estrogen stimulates the growth and survival of endometrial cells, and its dysregulation can lead to increased cell proliferation, angiogenesis, and tissue adhesion properties. The imbalance of estrogen receptors, particularly the estrogen receptor beta (ERβ), has been linked to endometriosis.\n",
      "\n",
      "Current therapeutic strategies targeting these pathways include:\n",
      "\n",
      "1. Anti-inflammatory agents: Nonsteroidal anti-inflammatory drugs (NSAIDs) and corticosteroids can help reduce inflammation and alleviate symptoms.\n",
      "2. Hormonal therapies: GnRH agonists, antagonists, and oral contraceptives can regulate estrogen levels and reduce endometriosis symptoms.\n",
      "3. Estrogen receptor modulators: Selective estrogen receptor modulators (SERMs) can target specific estrogen receptors to mitigate their effects on endometrial growth.\n",
      "4. Immunomodulatory therapies: Agents such as thalidomide and lenalidomide have shown promise in reducing inflammation and modulating the immune response in endometriosis.\n",
      "\n",
      "Newer therapeutic strategies, including small molecule inhibitors of inflammatory pathways and targeted estrogen receptor modulators, are being investigated to improve treatment outcomes for women with endometriosis.\n"
     ]
    }
   ],
   "source": [
    "query=\"How do aberrant inflammatory cytokine profiles and dysregulated estrogen receptor signaling contribute to the progression of endometriosis, and what are the current therapeutic strategies targeting these pathways?\"\n",
    "result = qa_chain({\"query\": query})\n",
    "print(result[\"result\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
